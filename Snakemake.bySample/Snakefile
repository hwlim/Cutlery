########################
## Basic parameters


## Sample information file with five columns: id / name / group / fq1 / fq2
src_sampleInfo	= "sample.tsv"
cluster_yml		= os.environ["CUTLERY"] + "/Snakemake.bySample/cluster.yml"

## Essential reference data
## Other user-defined files can be used.

## Mouse
genomeFa	= "/data/limlab/Resource/GenomeData/mm/mm10/Genome/genome.fa"
chrom_size	= "/data/limlab/Resource/GenomeData/mm/mm10/Genome/chrom.size"
## Peak mask e.g. ENCODE blacklist. "NULL" if N/A
peak_mask	= "/data/limlab/Resource/GenomeData/mm/mm10/ENCODE-blacklist.bed"
genome		= "mm10"
star_index	= "/data/limlab/Resource/STAR_Index/2.7.4/mm10_allChr_vM20"

## Human
#genomeFa	= "/data/limlab/Resource/GenomeData/hg/hg38/Genome/genome.fa"
#chrom_size	= "/data/limlab/Resource/GenomeData/hg/hg38/Genome/chrom.size"
#peak_mask	= "/data/limlab/Resource/GenomeData/hg/hg38/ENCODE-blacklist.bed"
#genome		= "hg38"
#star_index	= "/Volumes/limlab/Resource/STAR_Index/2.7.4/hg38_allChr_v29"

## Other STAR index also available under /data/limlab/Resource/STAR_Index/2.7.4
## If not, send a request to Lim Lab


## Other essential pameters
adapter     = "AGATCGGAAGAGC"	# illumina universal adapter in default
#adapter     = "CTGTCTCTTATA"	# Nextera adapter for ATAC-seq or Cut&Tag
#trim_maxLen=100	## Maximum read length after trimming. ** NOT YET IMPLEMENTED **
trim_minLen		= 20	# minimum fragment length. shorter fragments after trimming will be discarded
trim_minQual	= 20	# minimum quality for quality trimming
opt_cutadapt	= ""	# additional option for cutadapt


## Regular expressions for chromosome names
## Target chromosomes + spikein chromosome (if needed)
## This is also useful in excluding all the scaffold and random chromosomes
chrRegexAll		= "^chr[0-9XY]+$"
## Target chromosomes
chrRegexTarget	= "^chr[0-9XY]+$"

## Spike-in setting
## Regular expression of spike-in chromosomes, i.e. ec-chr for E coli chromosme (defined by Lim), "NULL" if not needed
## If not "NULL", spike-in fragment is separated when making a fragment bed files ** NOT Yet Implemented **
spikePrefix		= "NULL"

########################
## STAR options
star_module	= "STAR/2.7.4"

## STAR alignment options
## Default option for CUT&RUN (and ATAC-seq)
star_option	= "--alignSJDBoverhangMin 999 --alignIntronMax 1 --alignMatesGapMax 1000 --outFilterMultimapNmax 1 --outFilterMismatchNoverLmax 0.05 --outReadsUnmapped None --alignEndsProtrude 2 ConcordantPair"
## Note:
## Additoinal star_option to prevent soft-clipping: "--alignEndsType EndToEnd"
## BAM sort by "--outSAMtype" is handled by the star.align.sh by -s option.
## To keep unmapped reads in the output bam file, add "--outSAMunmapped Within"

## MEME Motif DB needed for MEME motif search
## No need to change if MEME motif search is not intended, i.e. MEME.random5k/meme-chip.html in the output
meme_db = os.environ["LIMLAB_BASE"] + "/Motif/MEME_DB/Merged_By_Lim.meme"


#########################
## Job flag options
doTrim		= True		## Perform adapter trimming, recommended
doDedup		= False		## Perform deduplication, NOT recommended

#########################
## Directories
fastqDir	= "0.Fastq"			# Directory containing fastq files
trimDir		= "0.Fastq.Trim"	# Directory for trimmed fastq files
alignDir	= "1.1.Align"		# Directory for alignment results
filteredDir	= "1.2.Align.filtered"	# Directory for filtered alignment results, i.e. chromosome, 
dedupDir	= "1.3.Align.dedup"	# ignored if doDeup==False
qcDir		= "2.1.QualityControl"

sampleDir	= "3.Sample"

###########################################################
## ** Developmental feature. Please ignore this section
## Parameters for k-mer bias correction
#kmer_genome	= "/data/limlab/Resource/Jellyfish.Kmer/%s.6mer.txt" % genome
kmer_genome = "NULL"
kmer_pseudo	= 1




################################################
## Loading sample Information & cluster config

## Sample table
import pandas as pd
import sys
samples = pd.read_csv(src_sampleInfo, sep="\t", comment="#", na_filter=False)

## Cluster configuration
import yaml
with open(os.path.expanduser(cluster_yml), 'r') as fh:
	cluster = yaml.safe_load(fh)


#################################################
## Configuration & sample sheet validation
include: os.environ["CUTLERY"] + "/Snakemake.bySample/validate.smk"


#########################
## Rules start

### Sample list and types (No need to change) 
# All sample names (Name field in sample.tsv file)
sampleList = samples.Name.tolist()
# Samples for TF (or narrow peaks)
sampleListFactor = samples.Name[samples.PeakMode=="factor"].tolist()
# Samples for histone modification (or broad peaks)
sampleListHistone = samples.Name[samples.PeakMode=="histone"].tolist()
# Number of highest scoring peaks to visualize
numHighestPeaks = 5

rule all:
	input:
		##### Basic Output Files #####
		## QC output
		qcDir + "/alignStat.txt",
		expand(qcDir + "/uniqFragCnt.{ext}", ext=[ "txt", "pdf" ]),
		expand(sampleDir + "/{sampleName}/QC/fragLen.dist.{ext}", sampleName=sampleList, ext=["txt","png"]),
		expand(sampleDir + "/{sampleName}/QC/base_freq.{ext}",  sampleName=sampleList, ext=["png","html"]),
		## BigWig files	
		expand(sampleDir + "/{sampleName}/igv.{fragment}.ctr.bw", sampleName=sampleList, fragment=["all","nfr","nuc"]),
		expand(sampleDir + "/{sampleName}/igv.{fragment}.con.bw", sampleName=sampleList, fragment=["all","nfr","nuc"]),
		## Peak calling
		expand(sampleDir + "/{sampleName}/HomerPeak.factor/peak.exBL.1rpm.{ext}", sampleName=sampleListFactor, ext=["bed","stat"]),
		expand(sampleDir + "/{sampleName}/HomerPeak.histone/peak.exBL.{ext}", sampleName=sampleListHistone, ext=["bed","stat"]),
		expand(sampleDir + "/{sampleName}/HomerPeak.factor/heatmap.exBL.1rpm.png", sampleName=sampleListFactor),
		expand(sampleDir + "/{sampleName}/HomerPeak.histone/heatmap.exBL.png", sampleName=sampleListHistone),

		## Motif search
		expand(sampleDir + "/{sampleName}/Motif/Homer.all/homerResults.html", sampleName=sampleListFactor),
		expand(sampleDir + "/{sampleName}/Motif/MEME.random5k/meme-chip.html", sampleName=sampleListFactor),
		## BigWig 1bp raw/abs (motivated for BPnet input file)
		#expand(sampleDir + "/{sampleName}/igv.1bp.raw.abs.{strand}.bw", sampleName=sampleList, strand=["plus","minus"]),

		## Draw peak examples
		expand(sampleDir + "/{sampleName}/HomerPeak.factor/peak.examples.{ext}", sampleName=sampleListFactor, ext=["png","pdf"]),
		expand(sampleDir + "/{sampleName}/HomerPeak.histone/peak.examples.{ext}", sampleName=sampleListHistone, ext=["png","pdf"]),

		## Calculate fragment QC
		expand(sampleDir + "/{sampleName}/QC/fragMix.txt", sampleName=sampleList),

		## Create report per sample
		expand(sampleDir + "/{sampleName}/QC/Report.html", sampleName=sampleListHistone),
		expand(sampleDir + "/{sampleName}/QC/Report.html", sampleName=sampleListFactor),
		# expand(sampleDir + "/{sampleName}/QC/Report_pooled.html", sampleName=sampleListHistone),
		# expand(sampleDir + "/{sampleName}/QC/Report_pooled.html", sampleName=sampleListFactor),

		## Create final report
		"Report.html"
		# "Report_pooled.html"

'''
Output files under Development
		#spikeinCntDir + "/spikein.txt"
		## Footprint
		expand(sampleDir + "/{sampleName}/Footprint.Homer.default/cnr.4.complete", sampleName=sampleListFactor),
		expand(sampleDir + "/{sampleName}/Footprint.Homer.corrected{kmer_pseudo}/cnr.4.complete", sampleName=sampleListFactor, kmer_pseudo=kmer_pseudo)
		expand(sampleDir + "/{sampleName}/igv.1bp.{strand}.bw", sampleName=sampleListFactor, strand=["plus","minus"]),
		expand(sampleDir + "/{sampleName}/igv.1bp.corrected{kmer_pseudo}.{strand}.bw", sampleName=sampleListFactor, kmer_pseudo=kmer_pseudo, strand=["plus","minus"]),
		expand(sampleDir + "/{sampleName}/QC/enrich.acor.{ext}", sampleName=sampleList, ext=["txt","png"]),
'''

## Include Snakemake rules from separate files
include: os.environ["CUTLERY"] + "/Snakemake.bySample/rules.pre.smk"
include: os.environ["CUTLERY"] + "/Snakemake.bySample/rules.post.smk"
