########################
## Basic parameters

## Sample information file with five columns: id / name / group / fq1 / fq2
src_sampleInfo	= "../sample.tsv"
cluster_yml		= "~/bin/CnR/Snakemake.bySample/cluster.yml"

## Genome folder depending on platform: CCHMC:HPC vs my desktop
import socket
hostname = socket.gethostname()	
if( hostname == "EA19-00359" ):
	# my desktop
	genomeFa	= "/Users/limc8h/Research/Common_Data/hg19/genome/genome.fa"
	chrom_size	= "/Users/limc8h/Research/Common_Data/hg19/chrom.sizes"
	peak_mask	= "/Users/limc8h/Research/Common_Data/hg19/ENCODE-blacklist.bed"
	baseDir		= "/Volumes"
else:
	# cluster system
	genomeFa	= "/data/limlab/Resource/GenomeData/hg/hg19/Genome/genome.fa"
	chrom_size	= "/data/limlab/Resource/GenomeData/hg/hg19/Genome/chrom.size"
	peak_mask	= "/data/limlab/Resource/GenomeData/hg/hg19/ENCODE-blacklist.bed"
	baseDir		= "/data"

## Other essential pameters
genome			= "hg19"
adapter			= "AGATCGGAAGAGC"	# illumina universal adapter
#adapter			= "CTGTCTCTTATA"	# Nextera adapter for ATAC-seq or Cut&Tag
#trim_maxLen=100	## Maximum read length after trimming. ** NOT YET IMPLEMENTED **
trim_minLen		= 20
trim_minQual	= 20
## Regular expression to filter-out non-regular chromosomes such as random/scaffolds
chrRegexAll		= "^chr[0-9XY]+$"
## Regular expression for target organism to exclude spike-in genome
chrRegexTarget	= "^chr[0-9XY]+$"
spikePrefix		= "NULL"

########################
## STAR index & options
star_index	= "/data/limlab/Resource/STAR_Index/2.7.4/hg19_allChr_v19"
star_module	= "STAR/2.7.4"

## ChIP-seq / ATAC-seq / Cut&Run
star_option	= "--alignSJDBoverhangMin 999 --alignIntronMax 1 --alignMatesGapMax 1000 --outFilterMultimapNmax 1 --outFilterMismatchNoverLmax 0.05 --outReadsUnmapped None --alignEndsProtrude 2 ConcordantPair"
## Note:
## Additoinal star_option to prevent soft-clipping: "--alignEndsType EndToEnd"
## BAM sort by "--outSAMtype" is handled by the star.align.sh by -s option.
## To keep unmapped reads in the output bam file, add "--outSAMunmapped Within"

#########################
## Job flags
doTrim		= True
doDedup		= False

#########################
## Directories
fastqDir	= baseDir + "/limlab/project/0.Fastq"
trimDir		= "0.Fastq.Trim"
alignDir	= "../Protrusion2/1.1.Align"
filteredDir	= "../Protrusion2/1.2.Align.filtered"
dedupDir	= "../Protrusion2/1.3.Align.dedup"
qcDir		= "2.1.QualityControl"

sampleDir	= "3.Sample"

#########################################
## Parameters for k-mer bias correction
kmer_genome	= "%s/limlab/Resource/Jellyfish.Kmer/%s.6mer.txt" % ( baseDir, genome )
kmer_pseudo	= 1



## CODE used in the initial version
#def getfq(wildcards):
#	return "0.Fastq/" + samples_indexById.loc[wildcards.sampleId, ["Fq1","Fq2"]]
#
#def getfq_trim(wildcards):
#	sampleId = samples_indexByName.loc[wildcards.sampleName, ["Id"]]
#	return [ "0.Fastq/Trim/" + sampleId + "_1.trim.fq.gz", "0.Fastq/Trim/" + sampleId + "_2.trim.fq.gz" ]

################################################
## Loading sample Information & Validation
import pandas as pd
import sys
samples = pd.read_csv(src_sampleInfo, sep="\t", comment="#", na_filter=False)

## Id / Name column must be unique
if not samples.Id.is_unique:
	print( "Error: Id column in sample.tsv is not unique" )
	sys.exit(1)
if not samples.Name.is_unique:
	print( "Error: Name column in sample.tsv is not unique" )
	sys.exit(1)

## Group column must not overlap with Name column
#if not len(set(samples.Group).intersection(set(samples.Name)))==0:
#	print( "Error: Sample Group name must not overlap with Name" )
#	sys.exit(1)

#################################
## Cluster configuration file
#cluster = json.load(open("./cluster.json"))
import yaml
with open(os.path.expanduser(cluster_yml), 'r') as fh:
	cluster = yaml.load(fh)






#########################
## Rules start
rule all:
	input:
		## QC output
		expand(sampleDir + "/{sampleName}/QC/fragLen.dist.{ext}", sampleName=samples.Name.tolist(), ext=["txt","png"]),
		expand(sampleDir + "/{sampleName}/QC/enrich.acor.{ext}", sampleName=samples.Name.tolist(), ext=["txt","png"]),
		expand(sampleDir + "/{sampleName}/QC/base_freq.png",  sampleName=samples.Name.tolist()),
		alignDir + "/alignStat.txt"
		#spikeinCntDir + "/spikein.txt"
		## bigWig files	
		expand(sampleDir + "/{sampleName}/igv.{fragment}.ctr.bw", sampleName=samples.Name.tolist(), fragment=["all","nfr","nuc"]),
		expand(sampleDir + "/{sampleName}/igv.1bp.{strand}.bw", sampleName=samples.Name[samples.PeakMode=="factor"].tolist(), strand=["plus","minus"]),
		expand(sampleDir + "/{sampleName}/igv.1bp.corrected{kmer_pseudo}.{strand}.bw", sampleName=samples.Name[samples.PeakMode=="factor"].tolist(), kmer_pseudo=kmer_pseudo, strand=["plus","minus"]),
		expand(sampleDir + "/{sampleName}/igv.allFrag.bw", sampleName=samples.Name.tolist()),
		## peak files
		expand(sampleDir + "/{sampleName}/HomerPeak.factor/peak.exBL.1rpm.bed", sampleName=samples.Name[samples.PeakMode=="factor"].tolist()),
		expand(sampleDir + "/{sampleName}/HomerPeak.histone/peak.exBL.bed", sampleName=samples.Name[samples.PeakMode=="histone"].tolist()),
		expand(sampleDir + "/{sampleName}/HomerPeak.factor/peak.exBL.1rpm.bed.all.noBG/homerResults.html", sampleName=samples.Name[samples.PeakMode=="factor"].tolist()),
		expand(sampleDir + "/{sampleName}/HomerPeak.factor/heatmap.exBL.1rpm.png", sampleName=samples.Name[samples.PeakMode=="factor"].tolist()),
		## Footprint
		expand(sampleDir + "/{sampleName}/Footprint.Homer.default/cnr.4.complete", sampleName=samples.Name[samples.PeakMode=="factor"].tolist()),
		expand(sampleDir + "/{sampleName}/Footprint.Homer.corrected{kmer_pseudo}/cnr.4.complete", sampleName=samples.Name[samples.PeakMode=="factor"].tolist(), kmer_pseudo=kmer_pseudo)


include: os.environ["MY_SCRIPT_BASE"] + "/CnR/Snakemake/rules.pre.smk"
include: os.environ["MY_SCRIPT_BASE"] + "/CnR/Snakemake.bySample/rules.post.smk"

